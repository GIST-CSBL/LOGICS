{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "739a5889",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ac3cbfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logics_pack import global_settings, chemistry, logics, predictor, analysis, smiles_vocab, smiles_lstm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "project_paths = global_settings.build_project_paths(project_dir='../')\n",
    "expset_obj = global_settings.ExperimentSettings(project_paths['EXPERIMENT_SETTINGS_JSON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582a06a5",
   "metadata": {},
   "source": [
    "Perform LOGICS fine-tuning to build agent generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d24c412",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGICS fine-tuning config\n",
    "config = global_settings.Object()\n",
    "\n",
    "config.ablation = None  # we will use full LOGICS model\n",
    "\n",
    "config.tokens_path = project_paths['SMILES_TOKENS_PATH']\n",
    "config.pretrain_setting_path = project_paths['PRETRAIN_SETTING_JSON']\n",
    "config.pretrained_model_path = project_paths['PROJECT_DIR'] + 'model-prior/prior_e10.ckpt'\n",
    "config.featurizer = predictor.featurizer\n",
    "config.predictor_path = project_paths['PROJECT_DIR'] + \\\n",
    "                            \"model-pik3ca/predictor/pik3ca_rfr_cv%s.pkl\"%expset_obj.get_setting(\"pik3ca-pred-best-cv\")\n",
    "\n",
    "config.max_epoch = 200\n",
    "config.save_period = 4\n",
    "config.save_ckpt_fmt = project_paths['PROJECT_DIR'] + 'model-pik3ca/logics/pik3ca_logics_e%d.ckpt'\n",
    "config.sample_fmt = project_paths['PROJECT_DIR'] + 'model-pik3ca/logics/pik3ca_logics_e%d.txt'\n",
    "config.memory_fmt = project_paths['PROJECT_DIR'] + 'model-pik3ca/logics/pik3ca_logics_mem_e%d.csv'\n",
    "config.memory_size = 100000\n",
    "config.save_size = 20000\n",
    "config.gen_size = config.save_size\n",
    "config.exp_size = config.save_size\n",
    "config.finetune_lr = 0.0001\n",
    "config.finetune_bs = 32\n",
    "config.sampling_bs = 256\n",
    "\n",
    "config.device_name = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1e7d22",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform fine-tuning\n",
    "logics.LOGICS_training(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1e8bb0",
   "metadata": {},
   "source": [
    "Load LOGICS agent generator and sample some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7145b0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_obj = smiles_vocab.Vocabulary(init_from_file=config.tokens_path)\n",
    "smtk = smiles_vocab.SmilesTokenizer(vocab_obj)\n",
    "\n",
    "with open(config.pretrain_setting_path, 'r') as f:\n",
    "    model_setting = json.load(f)\n",
    "    \n",
    "# load agent model (epoch=200)\n",
    "agent_ckpt = torch.load(config.save_ckpt_fmt%200, map_location='cpu')\n",
    "lstm_agent = smiles_lstm.SmilesLSTMGenerator(vocab_obj, model_setting['emb_size'], model_setting['hidden_units'], device_name='cpu')\n",
    "lstm_agent.lstm.load_state_dict(agent_ckpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f07d9a60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)c2cccc(C(=O)N3CCCC3)c2)C1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(Cc2ncccc2F)C1',\n",
       " 'CC1COCCN1c1nc(-c2cnc(=N)[nH]c2)c2c(n1)N(C1(C)CCN(S(=O)(=O)c3cn(C)cn3)CC1)CC2',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOC(CCF)C4)nc32)CCN(C(=O)c2cccc(C(F)(F)F)c2Cl)C1',\n",
       " 'CC(SNC(=O)c1ccc(S(=O)(=O)N2CCOCC2)cc1)C(=O)Nc1ccc(S(=O)(=O)N2CCOCC2)cc1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(NCC4CC4)nc32)CCN(C(=O)c2ccc(NS(=O)(=O)C(F)(F)F)cc2F)C1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)c2cc(O)ccc2O)C1',\n",
       " 'COC(=O)c1ccc(COc2ccc(CCNC(=O)N3CCN(C(=O)OC(C)(C)C)CC3)cc2)cc1',\n",
       " 'CN(C)C(=O)c1ccc(S(=O)(=O)NCCc2ccc(OCc3ccc(Cl)c(Cl)c3)cc2)cc1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(Cc2ccc(F)cn2)C1',\n",
       " 'CC(C)(C)OC(=O)N1CCC(C(=O)NCCc2ccc(OCc3cccc(Cl)c3)cc2)CC1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)C2CCN(S(=O)(=O)Cc3ccsc3)C2)C1',\n",
       " 'CC(C)OC(=O)N1CCC(Oc2ccc(OCc3ccc4c(c3)OCO4)cn2)C1',\n",
       " 'COC(=O)c1cccc(COc2cccc(CCNS(=O)(=O)N3CCOCC3)c2)c1',\n",
       " 'COc1cccc(COc2cccc(CCNS(=O)(=O)c3cccc(OC(F)(F)F)c3)c2)c1',\n",
       " 'O=S(=O)(CCNCCc1ccc(OCc2ccccc2)cc1)N1CCOCC1',\n",
       " 'Cc1ccc(S(=O)(=O)N2CCOCC2)cc1C(=O)NCCc1ccc(OCc2ccc3ccc(F)cc3n2)cc1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)c2ccc(NS(=O)(=O)CCF)cc2)CC1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)CCCCCCCCO)C1',\n",
       " 'CC(C)COC(=O)N1CCC(CO)(Cc2ccc(OCc3ccccc3)cc2)CC1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4CO)nc32)CCN(C(=O)c2ccc(F)c(F)c2)CC1',\n",
       " 'NS(=O)(=O)c1ccc(COc2ccc(C(=O)NCCc3ccc(O)cc3)cc2)cc1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)C(N)CCC(N)=O)C1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4CO)nc32)CCN(C(=O)CCl)C1',\n",
       " 'CC1COCCN1c1nc(-c2cnc(=N)[nH]c2)c2c(n1)N(C1(C)CCN(S(=O)(=O)c3ccc(Cl)cc3)CC1)CC2',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)c2cc3c(N)nccc3s2)C1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C2CCN(S(=O)(=O)C(C)(C)C)CC2)C1',\n",
       " 'O=C(NCCc1ccc(S(=O)(=O)N2CCOCC2)cc1)c1ccc(OCc2ccc(F)cc2F)cc1',\n",
       " 'CC1(C(=O)N2CCC(C)(N3CCc4c(-c5cnc(=N)[nH]c5)nc(N5CCOCC5)nc43)C2)CC1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)c2ccc(NS(=O)(=O)CCF)cc2F)C1',\n",
       " 'CC(C)(C)OC(=O)N1CCC(CC(=O)NCCc2ccc(OCc3cccc(Cl)c3)cc2)CC1',\n",
       " 'Cc1ccccc1N1CCN(S(=O)(=O)NCCc2ccc(OCc3cccc(Cl)c3)cc2)CC1',\n",
       " 'CCS(=O)(=O)N1CCC(C)(N2CCc3c(-c4cnc(=N)[nH]c4)nc(C(C)(C)O)nc32)C1',\n",
       " 'O=C(NCCc1ccc(S(=O)(=O)N2CCOCC2)cc1)c1ccc(OCc2ccc(Cl)cc2)cc1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(NCC(F)F)nc32)CCN(C(=O)CCc2cccnc2)C1',\n",
       " 'O=C(c1cscn1)N1CCC2(CC1)CN(c1ccnc(-c3ccc(F)cc3F)c1)C2',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)C=Cc2cccc(Cl)c2)C1',\n",
       " 'Cn1cc([N+](=O)[O-])cc1C(=O)N1CCCC(C)(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)C1',\n",
       " 'CC1COCCN1c1nc(-c2cnc(=N)[nH]c2)c2c(n1)N(C1(C)CCN(C(=O)c3ccoc3)C1)CC2',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(NCCc4ccccc4)nc32)CCN(C(=O)N2CCOCC2)C1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(NC4CCOCC4)nc32)CCN(C(=O)OCCF)C1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)c2cc(-c3ccc(F)cc3)cs2)C1',\n",
       " 'O=C(NCCc1ccc(OCc2cccc(F)c2)cc1)C1CCN(S(=O)(=O)c2ccc(-c3ccccc3)cc2)CC1',\n",
       " 'CN(Cc1cccc(F)c1)C(=O)C(NC(=O)C1CCN(C(=O)OCc2ccccc2)CC1)C(C)(C)C',\n",
       " 'CC1COCCN1c1nc(-c2cnc(=N)[nH]c2)c2c(n1)N(C1(C)CCN(C(=O)C(F)F)C1)CC2',\n",
       " 'CC(Sc1nnc(-c2cccc(OCc3ccccc3)c2)n1C)C(=O)Nc1ccc(S(=O)(=O)N2CCOCC2)cc1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)CCCC(=O)N2CCSC2)C1',\n",
       " 'COc1ccc(S(=O)(=O)NCCc2ccc(OCc3cn(C4CCN(C(=O)OC(C)(C)C)CC4)nn3)cc2)cc1',\n",
       " 'CC(O)C(=O)N1CCC(C)(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)C1',\n",
       " 'CC1(N2CCc3c(-c4cnc(=N)[nH]c4)nc(N4CCOCC4)nc32)CCN(C(=O)c2ccc3nccnc3c2)C1']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# sampling\n",
    "ssplr = analysis.SafeSampler(lstm_agent, batch_size=16)\n",
    "generated_smiles = ssplr.sample_clean(50, maxlen=150)\n",
    "display(generated_smiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52bf1f2",
   "metadata": {},
   "source": [
    "Subsidiary files building for evaluation phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5c0025a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.vc_fmt = project_paths['PROJECT_DIR'] + 'model-pik3ca/logics/pik3ca_logics_vc_e%d.smi'  # save valid & canonical smiles\n",
    "config.npfps_fmt = project_paths['PROJECT_DIR'] + 'model-pik3ca/logics/pik3ca_logics_npfps_e%d.npy'  # save fingerprint in npy\n",
    "config.fcvec_fmt = project_paths['PROJECT_DIR'] + 'model-pik3ca/logics/pik3ca_logics_fcvec_e%d.npy'  # save Frechet ChemNet vectors\n",
    "\n",
    "# epochs = list(range(0, config.max_epoch+1, config.save_period))\n",
    "epochs = [200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "071aa750",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bsbae402/anaconda3/envs/logics/lib/python3.7/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/bsbae402/anaconda3/envs/logics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3313: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-23 13:34:22.617318: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n",
      "2023-03-23 13:34:22.649769: E tensorflow/stream_executor/cuda/cuda_driver.cc:318] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2023-03-23 13:34:22.649803: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:169] retrieving CUDA diagnostic information for host: shepherd5\n",
      "2023-03-23 13:34:22.649811: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:176] hostname: shepherd5\n",
      "2023-03-23 13:34:22.649908: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:200] libcuda reported version is: 465.19.1\n",
      "2023-03-23 13:34:22.649940: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:204] kernel reported version is: 465.19.1\n",
      "2023-03-23 13:34:22.649948: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:310] kernel version seems to match DSO: 465.19.1\n",
      "2023-03-23 13:34:22.650826: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2023-03-23 13:34:22.661493: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300040000 Hz\n",
      "2023-03-23 13:34:22.664785: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x6b32b20 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2023-03-23 13:34:22.664820: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/bsbae402/anaconda3/envs/logics/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '-1'  # use tensorflow cpu\n",
    "\n",
    "import fcd\n",
    "from logics_pack import frechet_chemnet\n",
    "fc_ref_model = fcd.load_ref_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe7d0435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "- count invalids:  90\n"
     ]
    }
   ],
   "source": [
    "for epo in epochs:\n",
    "    print(epo)\n",
    "    with open(config.sample_fmt%epo, 'r') as f:\n",
    "        gens = [line.strip() for line in f.readlines()]\n",
    "    vcs, invids = chemistry.get_valid_canons(gens)\n",
    "    print(\"- count invalids: \", len(invids))\n",
    "    with open(config.vc_fmt%epo, 'w') as f:\n",
    "        f.writelines([line+'\\n' for line in vcs])\n",
    "    fps = chemistry.get_fps_from_smilist(vcs)\n",
    "    np.save(config.npfps_fmt%epo, chemistry.rdk2npfps(fps))\n",
    "    fcvecs = fcd.get_predictions(fc_ref_model, vcs)  # ChemNet vectors\n",
    "    np.save(config.fcvec_fmt%epo, fcvecs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4b4a4df",
   "metadata": {},
   "source": [
    "Evaluate FCD and OTD on validation set, and pick the best epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a8dd2578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading validation dataset\n",
    "with open(project_paths['PIK3CA_FOLD_JSON'], 'r') as f:\n",
    "    pik3_folds = json.load(f)\n",
    "data_npfps = np.load(project_paths['PIK3CA_DATA_FP'])\n",
    "data_fcvecs = np.load(project_paths['PIK3CA_DATA_FCVEC'])\n",
    "\n",
    "val_fold_id = expset_obj.get_setting('pik3ca-pred-best-cv')\n",
    "val_npfps = data_npfps[pik3_folds[val_fold_id]]\n",
    "val_rdkfps = chemistry.np2rdkfps(val_npfps)\n",
    "val_fcvecs = data_fcvecs[pik3_folds[val_fold_id]]\n",
    "\n",
    "dsize = len(val_rdkfps)  # demand size for OT\n",
    "ssize = dsize*global_settings.OT_CALC_REPEATS  # supply size for repeated OT   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a9db5c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "val_fcd_list = []\n",
    "val_otd_list = []\n",
    "for epo in epochs:\n",
    "    print(epo)\n",
    "    # load fc vectors of generation\n",
    "    gen_fcvecs = np.load(config.fcvec_fmt%epo)\n",
    "    fcdval = frechet_chemnet.fcd_calculation(val_fcvecs, gen_fcvecs)\n",
    "    val_fcd_list.append(fcdval)\n",
    "    \n",
    "    gen_npfps = np.load(config.npfps_fmt%epo)[:ssize]  # only need this amount\n",
    "    gen_rdkfps = chemistry.np2rdkfps(gen_npfps)\n",
    "    simmat = analysis.calculate_simmat(gen_rdkfps, val_rdkfps)  # row:gen, col:data\n",
    "    distmat = analysis.transport_distmat(analysis.tansim_to_dist, simmat, global_settings.OT_CALC_REPEATS)\n",
    "    _, _, motds = analysis.repeated_optimal_transport(distmat, repeat=global_settings.OT_CALC_REPEATS)\n",
    "    val_otd_list.append(np.mean(motds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f2418d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation FCDxOTD\n",
    "val_FCDxOTD = np.array(val_fcd_list)*np.array(val_otd_list)\n",
    "# find the best epoch\n",
    "best_epoch = epochs[np.argmin(val_FCDxOTD)]\n",
    "# register the best epoch\n",
    "expset_obj.update_setting('pik3ca-logics-best-epoch', best_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d831e8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "print(expset_obj.get_setting('pik3ca-logics-best-epoch'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eaaf38f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e0e4b7e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logics",
   "language": "python",
   "name": "logics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
