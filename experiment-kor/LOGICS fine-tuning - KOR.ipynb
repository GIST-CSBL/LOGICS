{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcbb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27654889",
   "metadata": {},
   "outputs": [],
   "source": [
    "from logics_pack import global_settings, chemistry, logics, predictor, analysis, smiles_vocab, smiles_lstm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "\n",
    "project_paths = global_settings.build_project_paths(project_dir='../')\n",
    "expset_obj = global_settings.ExperimentSettings(project_paths['EXPERIMENT_SETTINGS_JSON'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa314a",
   "metadata": {},
   "source": [
    "Perform LOGICS fine-tuning to build agent generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa7dd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOGICS fine-tuning config\n",
    "config = global_settings.Object()\n",
    "\n",
    "config.ablation = None  # we will use full LOGICS model\n",
    "\n",
    "config.tokens_path = project_paths['SMILES_TOKENS_PATH']\n",
    "config.pretrain_setting_path = project_paths['PRETRAIN_SETTING_JSON']\n",
    "config.pretrained_model_path = project_paths['PROJECT_DIR'] + 'model-prior/prior_e10.ckpt'\n",
    "\n",
    "config.featurizer = predictor.featurizer\n",
    "config.predictor_path = project_paths['PROJECT_DIR'] + \"model-kor/predictor/kor_rfr_cv%s.pkl\"%expset_obj.get_setting(\"kor-pred-best-cv\")\n",
    "\n",
    "config.max_epoch = 200\n",
    "config.save_period = 4\n",
    "config.save_ckpt_fmt = project_paths['PROJECT_DIR'] + 'model-kor/logics/kor_logics_e%d.ckpt'\n",
    "config.sample_fmt = project_paths['PROJECT_DIR'] + 'model-kor/logics/kor_logics_e%d.txt'\n",
    "config.memory_fmt = project_paths['PROJECT_DIR'] + 'model-kor/logics/kor_logics_mem_e%d.csv'\n",
    "config.memory_size = 100000\n",
    "config.save_size = 20000\n",
    "config.gen_size = config.save_size\n",
    "config.exp_size = config.save_size\n",
    "config.finetune_lr = 0.0001\n",
    "config.finetune_bs = 32\n",
    "config.sampling_bs = 256\n",
    "\n",
    "config.device_name = 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a369579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# perform fine-tuning\n",
    "logics.LOGICS_training(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3807ceb5",
   "metadata": {},
   "source": [
    "Load LOGICS agent generator and sample some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d32a8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_obj = smiles_vocab.Vocabulary(init_from_file=config.tokens_path)\n",
    "smtk = smiles_vocab.SmilesTokenizer(vocab_obj)\n",
    "\n",
    "with open(config.pretrain_setting_path, 'r') as f:\n",
    "    model_setting = json.load(f)\n",
    "    \n",
    "# load agent model (epoch=100)\n",
    "agent_ckpt = torch.load(config.save_ckpt_fmt%100, map_location='cpu')\n",
    "lstm_agent = smiles_lstm.SmilesLSTMGenerator(vocab_obj, model_setting['emb_size'], model_setting['hidden_units'], device_name='cpu')\n",
    "lstm_agent.lstm.load_state_dict(agent_ckpt['model_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4e3548",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sampling\n",
    "ssplr = analysis.SafeSampler(lstm_agent, batch_size=16)\n",
    "generated_smiles = ssplr.sample_clean(50, maxlen=150)\n",
    "display(generated_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31bb609c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b24ae9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "logics_shep8",
   "language": "python",
   "name": "logics_shep8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
